{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You Only Look Once\n",
    "#### YOLO is a state of the art object detection algorithm. It detects multi class objects in a given single image. YOLO can be used for real-time object detection for robotic, self driving cars applications and more.\n",
    "#### It makes use of pre-trained weights as input for efficient object detection. In this Notebook, the Darknet deep learning framework has been used, which is from the creators of YOLO.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the necessary packages.\n",
    "#### Matplotlib - The package is used for plotting and visualizing the data in various ways.\n",
    "#### cv2 - The package is used to load the images and pre-process the images.\n",
    "#### Darknet - The package consists of Darknet deep learning framework for YOLO implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1e2d266e8a11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdarknet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDarknet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "from darknet import Darknet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Neural network \n",
    "#### yolov3.cfg : The configuration file consists of the neural net architecture developed by YOLO creators.\n",
    "#### yolov3.weights: The weight file consists of pre-trained network which can detect padestrians, cars, bags, etc as mentioned in coco_names file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the name of the config file where the neural network architecture is defined\n",
    "config_file = 'yolov3.cfg' \n",
    "\n",
    "#Set the name of the file where weights are defined from the pre-trained network\n",
    "weight_file = 'yolov3.weights'\n",
    "\n",
    "#Set the name of the file where COCO classes are defined\n",
    "names_file = 'coco_names'\n",
    "\n",
    "#Loading the network architecture given in config_file\n",
    "net = Darknet(config_file)\n",
    "\n",
    "#Loading the weights given in weight_file\n",
    "net.load_weights(weight_file)\n",
    "\n",
    "#Loading the class names\n",
    "class_names = load_class_names(names_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and resizing the images\n",
    "#### The images are loaded using cv2.imread() function from openCV library. Secondly, the images need to be converted into RGB format from BGR format using cv2.cvtColor() function. The neural network accepts [416,416,3] dimensional images. Hence, the images are rescaled accordingly using cv2.resize() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the input image for testing\n",
    "image = cv2.imread('padestrian.jpg')\n",
    "\n",
    "#Converting the color space from BGR to RGB\n",
    "image_rgb = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#Resizing the images according to the input size of the NN first layer\n",
    "image_resized = cv2.resize(image_rgb,((net.width, net.height)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the NMS threshold\n",
    "nms_thres = 0.6\n",
    "\n",
    "#Set the IOU threshold\n",
    "iou_thres = 0.4\n",
    "\n",
    "#Detection of the objects in an image\n",
    "boxes = detect_objects(net, image_resized, iou_thres, nms_thres)\n",
    "\n",
    "# Print the objects which are found and their confidence levels\n",
    "print_objects(boxes, class_names)\n",
    "\n",
    "#Plot the image with bounding boxes and corresponding object class labels\n",
    "plot_boxes(image_rgb, boxes, class_names, plot_labels = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
